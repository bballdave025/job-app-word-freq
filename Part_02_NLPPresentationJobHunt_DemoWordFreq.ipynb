{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02d10fc3",
   "metadata": {},
   "source": [
    "## Job-Hunt NLP Demo - Part 1\n",
    "\n",
    "Which demo will also be useful in doing some quick NLP work to see how my résumé's word distribution matches that from job descriptions.\n",
    "\n",
    "There's a wonderful project out there, [MyBinder](https://mybinder.org), which allows you to interactively run a Jupyter notebook completely online. It's nice to have when you'd like to play with code and see better the outputs that come from running that code. I've had some problems with images going down, but I'm going to work to keep this one up.\n",
    "\n",
    "The link to the online, interactive notebook - the binder - is at the badge you see right here\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/bballdave025/job-app-word-freq/main?labpath=A_02nd_NLPPresentationJobHunt_DemoWordFreq.ipynb)\n",
    "\n",
    "<hr/>\n",
    "\n",
    "## We are calling this version 0.1.003\n",
    "\n",
    "It's the FamilySearch CJKV jobs applied for in August 2023, but we're splitting it into smaller notebooks. Hopefully, MyBinder can load each more quickly. We'll see how things work with pickling variables between the parts.\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbd5a12",
   "metadata": {},
   "source": [
    "## Let's start by un-pickle-ing the things we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae198da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_filename_1_to_2 = \"important_part_1_vars.pkl\"\n",
    "\n",
    "unpickled_array = []\n",
    "\n",
    "with open(pickle_filename_1_to_2, 'rb') as pfh:\n",
    "    unpickled_array = pickle.load(pfh)\n",
    "##endof:  with open ... as pfh # (pickle file handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01bc06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_job_desc_filenames = unpickled_array[0]\n",
    "local_job_appl_filenames = unpickled_array[1]\n",
    "complete_description_text = unpickled_array[2]\n",
    "complete_application_text = unpickled_array[3]\n",
    "description_strings = unpickled_array[4]\n",
    "description_word_counts = unpickled_array[5]\n",
    "application_strings = unpickled_array[6]\n",
    "application_word_counts = unpickled_array[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4593ac2f",
   "metadata": {},
   "source": [
    "## Nicely-formatted Word Frequency Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74bcecc",
   "metadata": {},
   "source": [
    "The next code will take care of the issue I described thusly:\n",
    "> It's annoying me not to have a nice, aligned output for these 2d lists - basically, they're tables. I need to bring in some previous code that takes care of getting stuff printed nice. That will be after the Q&R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d119210c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from io import StringIO\n",
    "import re\n",
    "\n",
    "def print_2d_list_columns_aligned(list_2d_to_print,\n",
    "                                  joining_delimiter = \",  \",\n",
    "                                  do_output_as_str_and_print = False,\n",
    "                                  do_see_the_guts=False):\n",
    "    ##  The  do_see_the_guts boolean is partly for debugging,\n",
    "    ##+ partly for remembering and teaching how the process\n",
    "    ##+ works.\n",
    "    \n",
    "    ## Make all elements strings - so we can use len()\n",
    "    list_2d_all_strings = \\\n",
    "      [[str(item) for item in row] for row in list_2d_to_print]\n",
    "    \n",
    "    if do_see_the_guts:\n",
    "        print()\n",
    "        print(\"  list_2d_all_strings:\")\n",
    "        print(list_2d_all_strings)\n",
    "        print()\n",
    "    ##endof:  if do_see_the_guts\n",
    "    \n",
    "    #  We want to find the max string length for each column\n",
    "    #+ We can basically transpose the 2d_list to get the\n",
    "    #+ content of each column\n",
    "    list_of_column_elems_as_tuples = \\\n",
    "                 [column for column in zip(*list_2d_all_strings)]\n",
    "    \n",
    "    if do_see_the_guts:\n",
    "        print()\n",
    "        print(\"  list_of_column_elems_as_tuples:\")\n",
    "        print(list_of_column_elems_as_tuples)\n",
    "        print()\n",
    "    ##endof:  if do_see_the_guts\n",
    "    \n",
    "    ## find the max string length for each tuple (each column)\n",
    "    list_of_max_str_len_by_column = \\\n",
    "      [max([len(strng) for strng in tpl]) \n",
    "        for tpl in list_of_column_elems_as_tuples]\n",
    "    # -v- gives array with elements being each longest string\n",
    "    #[max([strng for strng in tpl], key=len) for tpl in list_of_column_elems_as_tuples]\n",
    "    # -v- 2d array with strings\n",
    "    #[[strng for strng in tpl] for tpl in list_of_column_elems_as_tuples]\n",
    "    \n",
    "    if do_see_the_guts:\n",
    "        print()\n",
    "        print(\"  list_of_max_str_len_by_column:\")\n",
    "        print(list_of_max_str_len_by_column)\n",
    "        print()\n",
    "    ##endof:  if do_see_the_guts\n",
    "    \n",
    "    # output_as_str_not_list = False\n",
    "    \n",
    "    # Create a formatter for each row\n",
    "    \n",
    "    #if not output_as_str_not_list:\n",
    "    joining_delimiter = \",\" + joining_delimiter\n",
    "    \n",
    "    fmt_str = \\\n",
    "      joining_delimiter.join('{{:{}}}'.format(max_len) \n",
    "                               for max_len in list_of_max_str_len_by_column)\n",
    "    #if not output_as_str_not_list:\n",
    "    fmt_str = \"[\" + fmt_str + \"],\"\n",
    "    \n",
    "    if do_see_the_guts:\n",
    "        print()\n",
    "        print(\"  fmt_str:\")\n",
    "        print(fmt_str)\n",
    "        print()\n",
    "    ##endof:  if do_see_the_guts\n",
    "    \n",
    "    # Get a string for each row, formatted correctly\n",
    "    list_of_formatted_row_strings = \\\n",
    "      [fmt_str.format(*row) for row in list_2d_all_strings]\n",
    "    \n",
    "    if do_see_the_guts:\n",
    "        print()\n",
    "        print(\"  list_of_formatted_row_strings:\")\n",
    "        print(list_of_formatted_row_strings)\n",
    "        print()\n",
    "    ##endof:  if do_see_the_guts\n",
    "    \n",
    "    s = StringIO()\n",
    "    print(*list_of_formatted_row_strings, file=s)\n",
    "    output_table_raw = s.getvalue()\n",
    "    \n",
    "    output_table_raw = re.sub(r\"^\\[\", r\"[[ \", output_table_raw)\n",
    "    output_table_raw = re.sub(r\"\\],$\", r\"]]\", output_table_raw)\n",
    "    #output_table_raw = re.sub(r\"([^ ])\\],\", r\"\\g<1> ],\", output_table_raw)\n",
    "    output_table_raw = re.sub(r\"\\],\", r\" ],\", output_table_raw)\n",
    "    output_table_raw = re.sub(r\",,\", r\" ,\", output_table_raw)\n",
    "    output_table_raw = re.sub(r\"]]\", r\" ]]\", output_table_raw)\n",
    "    \n",
    "    aligned_table_to_return = output_table_raw.replace(r\"], [\", \"],\\n [ \")\n",
    "    \n",
    "    print(aligned_table_to_return)\n",
    "    \n",
    "    if do_output_as_str_and_print:\n",
    "        return aligned_table_to_return\n",
    "    ##endof:  if do_output_as_str_and_print\n",
    "    \n",
    "##endof:  print_2d_list_colunns_aligned(<params>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45976607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##  Uncomment if you want to see the guts of a small example\n",
    "# ##+ that's been hacked into working all right\n",
    "# print_2d_list_columns_aligned([['hey', 7], ['work', 3], ['stupid', 2]], do_see_the_guts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a788ec2",
   "metadata": {},
   "source": [
    "### Here, we're giving the option to see the whole `word, word_count` list with however many words were found in the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8b66e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only change this boolean to True if you want to see a lot of output. ##\n",
    "do_print_long_full_version = False\n",
    "\n",
    "if do_print_long_full_version:\n",
    "    dashes=\"------------------------------------------------------------\"\n",
    "    short_dashes=\"-----\"\n",
    "    \n",
    "    this_d_str_counter = -1 # quick hack for zero-indexed\n",
    "    \n",
    "    for d_word_count_dict in description_word_counts:\n",
    "        this_d_str_counter += 1\n",
    "        \n",
    "        #  I haven't yet written this for several resumes, so\n",
    "        #+ it just compares each description with the first\n",
    "        #+ (or, likely, combined) thing in the resume stuff.\n",
    "        this_a_str_index = 0\n",
    "        a_word_count_dict = application_word_counts[this_a_str_index]\n",
    "        \n",
    "        print()\n",
    "        print()\n",
    "        print(dashes)\n",
    "        print(f\" For the job description with index, {this_d_str_counter}\")\n",
    "        print( \" (meaning it's from the file:\")\n",
    "        print(f\"   {local_job_desc_filenames[this_d_str_counter]}),\")\n",
    "        print(short_dashes)\n",
    "        this_d_wdct_items_list = list(d_word_count_dict.items())\n",
    "        this_d_wdct_2d_list = [list(ele) for ele in this_d_wdct_items_list]\n",
    "        print_2d_list_columns_aligned(this_d_wdct_2d_list)\n",
    "        print(dashes)\n",
    "        print()\n",
    "        print()\n",
    "        print(dashes)\n",
    "        print( \" For the job application material (résumé, cover letter, etc.)\")\n",
    "        print(f\" with index, {this_a_str_index}\")\n",
    "        print( \"(meaning it's from the file:\")\n",
    "        print(f\"   {local_job_appl_filenames[this_a_str_index]}),\")\n",
    "        print(short_dashes)\n",
    "        this_a_wdct_items_list = list(a_word_count_dict.items())\n",
    "        this_a_wdct_2d_list = [list (ele) for ele in this_a_wdct_items_list]\n",
    "        print_2d_list_columns_aligned(this_a_wdct_2d_list)\n",
    "        print(dashes)\n",
    "        print()\n",
    "        print()\n",
    "        print(dashes)\n",
    "        print(dashes)\n",
    "        print()\n",
    "        print()\n",
    "    ##endof:  for d_word_count_dict in description_word_counts\n",
    "##endof:  if do_print_long_full_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25d12b9",
   "metadata": {},
   "source": [
    "### Get the data useful and see basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b93958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_counter = -1 # hack for zero-indexing\n",
    "appl_index   =  0 #  combining application files\n",
    "                  #+ (actually, here, there's only one file)\n",
    "\n",
    "description_items_list = []\n",
    "application_items_list = []\n",
    "\n",
    "this_a_word_count = application_word_counts[appl_index]\n",
    "application_items = list(this_a_word_count.items())\n",
    "application_items_list.append(application_items)\n",
    "\n",
    "for this_d_word_count in description_word_counts:\n",
    "    desc_counter += 1\n",
    "    \n",
    "#     #  I haven't yet written this for several resumes, so\n",
    "#     #+ it just compares each description with the first\n",
    "#     #+ (or, likely, combined) thing in the resume stuff.\n",
    "#     this_a_word_count = application_word_counts[appl_index]\n",
    "    \n",
    "    description_items_list.append(list(this_d_word_count.items()))\n",
    "#     application_items = list(this_a_word_count.items())\n",
    "    \n",
    "    n_words_description = len(description_items_list[desc_counter])\n",
    "    n_words_application = len(application_items_list[appl_index])\n",
    "    \n",
    "    print()\n",
    "    print(\"NOTE THAT THESE ARE THE NUMBERS OF DISTINCT WORDS\")\n",
    "    print()\n",
    "    print(f\" For the job description with index, {desc_counter}\")\n",
    "    print( \" (meaning it's from the file:\")\n",
    "    print(f\"   {local_job_desc_filenames[desc_counter]}),\")\n",
    "    print(\"AND\")\n",
    "    print( \" For the job application material (résumé, cover letter, etc.)\")\n",
    "    print(f\" with index, {appl_index}\")\n",
    "    print( \"(meaning it's from the file:\")\n",
    "    print(f\"   {local_job_appl_filenames[appl_index]}),\")\n",
    "    print()\n",
    "    print(f\"n_words_description = {str(n_words_description)}\")\n",
    "    print(f\"n_words_application = {str(n_words_application)}\")\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "##endof:  for this_d_word_count in description_word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b563a62f",
   "metadata": {},
   "source": [
    "### Getting job-descriptions, job-applications rankings nicely formatted\n",
    "\n",
    "#### And a nice comparison of the rankings for both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11d7e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import copy\n",
    "\n",
    "#    ##  Not handling ties differently - whichever shows up first gets the\n",
    "#    ##+ higher ranking\n",
    "#\n",
    "#    # #  These start out impossible (can't have a negative index), \n",
    "#    # #+ so we'll know if we use it without changing\n",
    "#    # this_d_tie_dict_index = -1\n",
    "#    # this_d_tie_value = -1\n",
    "#    # this_a_tie_dict_index = -1\n",
    "#    # this_a_tie_value = -1\n",
    "\n",
    "table_version_desc = None\n",
    "table_version_appl = None\n",
    "table_version_both = None\n",
    "\n",
    "list_of_table_version_desc = []\n",
    "list_of_table_version_appl = []\n",
    "list_of_table_version_both = []\n",
    "\n",
    "for this_description_items in description_items_list:\n",
    "    if table_version_desc is not None:\n",
    "        table_version_desc.clear()\n",
    "    if table_version_appl is not None:\n",
    "        table_version_appl.clear()\n",
    "    if table_version_both is not None:\n",
    "        table_version_both.clear()\n",
    "    \n",
    "    table_version_desc = [[\"desc_word\", \"desc_cnt\", \"desc_rank\"],]\n",
    "    table_version_appl = [[\"appl_word\", \"appl_cnt\", \"appl_rank\"],]\n",
    "    table_version_both = [[\"rank\", \"desc_word\", \"desc_cnt\", \n",
    "                           \"appl_word\", \"appl_cnt\"],\n",
    "                         ]\n",
    "    \n",
    "    for this_idx in range(max(len(this_description_items),\n",
    "                              len(application_items)\n",
    "                             ) # - 1\n",
    "                          ):\n",
    "        \n",
    "        this_rank = this_idx + 1\n",
    "        \n",
    "        this_description_word  = \"\"\n",
    "        this_description_count = \"\"\n",
    "        this_description_rank  = \"\"\n",
    "        \n",
    "        if this_idx < len(this_description_items): # - 1:\n",
    "            this_description_word  = this_description_items[this_idx][0] #+1][0]\n",
    "            this_description_count = this_description_items[this_idx][1] #+1][1]\n",
    "            this_description_rank  = this_rank\n",
    "        else:\n",
    "            this_description_word  = \"-- N/A --\"\n",
    "            this_description_count = \"-- N/A --\"\n",
    "            this_description_rank  = \"-- N/A --\"\n",
    "        ##endof:  if/else this_idx < len(description_items)\n",
    "        \n",
    "        this_application_word  = \"\"\n",
    "        this_application_count = \"\"\n",
    "        this_application_rank  = \"\"\n",
    "        \n",
    "        if this_idx < len(application_items): # - 1:\n",
    "            this_application_word  = application_items[this_idx][0]\n",
    "            this_application_count = application_items[this_idx][1]\n",
    "            this_application_rank  = this_rank\n",
    "        else:\n",
    "            this_application_word  = \"-- N/A --\"\n",
    "            this_application_count = \"-- N/A --\"\n",
    "            this_application_rank  = \"-- N/A --\"\n",
    "        ##endof:  if/else this_idx < len(application_items)\n",
    "\n",
    "        if this_description_word != \"-- N/A --\":\n",
    "            table_version_desc.append([this_description_word, \n",
    "                                       this_description_count, \n",
    "                                       this_rank]\n",
    "                                     )\n",
    "        ##endof:  if this_description_word != \"-- N/A --\"\n",
    "\n",
    "        if this_application_word != \"-- N/A --\":\n",
    "            table_version_appl.append([this_application_word, \n",
    "                                       this_application_count, \n",
    "                                       this_rank\n",
    "                                      ]\n",
    "                                     )\n",
    "        ##endof:  if this_application_word != \"-- N/A --\"\n",
    "\n",
    "        table_version_both.append([this_rank, \n",
    "                                   this_description_word, \n",
    "                                   this_description_count,\n",
    "                                   this_application_word, \n",
    "                                   this_application_count\n",
    "                                  ]\n",
    "                                 )\n",
    "    ##endof:  for this_idx in max(<n_desc_words>, <n_appl_words>)\n",
    "    \n",
    "    ## deep copies, since it's an immutable list passed by reference\n",
    "    \n",
    "    deep_desc = copy.deepcopy(table_version_desc)\n",
    "    deep_appl = copy.deepcopy(table_version_appl)\n",
    "    deep_both = copy.deepcopy(table_version_both)\n",
    "    \n",
    "    list_of_table_version_desc.append(deep_desc)\n",
    "    list_of_table_version_appl.append(deep_appl)\n",
    "    list_of_table_version_both.append(deep_both)\n",
    "    \n",
    "##endof:  for this_description_items in description_items_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036a6d48",
   "metadata": {},
   "source": [
    "**The next 3 cells are other cells for which, if the code be uncommented, you will get a lot of output.**\n",
    "\n",
    "We will later see a nicer version of the top 25 words from each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700f321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pprint; pprint.pprint(list_of_table_version_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f185481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pprint; pprint.pprint(list_of_table_version_appl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b73c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pprint; pprint.pprint(list_of_table_version_both)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee18fc45",
   "metadata": {},
   "source": [
    "### Finally, the nice output for the top 25s\n",
    "\n",
    "After a few cells, we will see it. That will be the end of Part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a9bb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import copy\n",
    "\n",
    "###\n",
    "##  Set up the display the first n_lines_to_display \n",
    "##+ of the tables, nicely\n",
    "\n",
    "#### This next one is the one you might change\n",
    "n_lines_to_display_orig = 25\n",
    "\n",
    "n_header_lines = 1\n",
    "n_lines_to_display = n_lines_to_display_orig\n",
    "n_lines_to_display_desc = n_lines_to_display_orig\n",
    "n_lines_to_display_appl = n_lines_to_display_orig\n",
    "\n",
    "## Here is where the code for doing it with lists of strings comes\n",
    "\n",
    "display_table_desc = None\n",
    "display_table_appl = None\n",
    "display_table_both = None\n",
    "\n",
    "list_of_display_table_desc = []\n",
    "list_of_display_table_appl = []\n",
    "list_of_display_table_both = []\n",
    "\n",
    "for desc_fname_idx_for_now in range(len(list_of_table_version_desc)):\n",
    "    #  find out which one is longer. Make that the length of the\n",
    "    #+ display_table_both\n",
    "    do_cut_down_desc = ( n_lines_to_display_orig >\n",
    "                            len(list_of_table_version_desc[desc_fname_idx_for_now]) \n",
    "    )\n",
    "    if do_cut_down_desc:\n",
    "        n_lines_to_display_desc = len(list_of_table_version_desc[desc_fname_idx_for_now])\n",
    "    ##endof:  if do_cut_down_desc\n",
    "    \n",
    "    do_cut_down_appl = ( n_lines_to_display_orig >\n",
    "                            len(list_of_table_version_appl[desc_fname_idx_for_now]) \n",
    "    )\n",
    "    if do_cut_down_appl:\n",
    "        n_lines_to_display_appl = len(list_of_table_version_appl[desc_fname_idx_for_now])\n",
    "    ##endof:  if do_cut_down_appl\n",
    "    \n",
    "    # start with a new, immutable, pass-by-reference table\n",
    "    if display_table_desc is not None:\n",
    "        display_table_desc.clear()\n",
    "    if display_table_appl is not None:\n",
    "        display_table_appl.clear()\n",
    "    if display_table_both is not None:\n",
    "        display_table_both.clear()\n",
    "    \n",
    "    # get headers\n",
    "    display_table_desc = [list_of_table_version_desc[desc_fname_idx_for_now][0]]\n",
    "    display_table_appl = [list_of_table_version_appl[desc_fname_idx_for_now][0]]\n",
    "        # made copies to make it easier\n",
    "    display_table_both = [list_of_table_version_both[desc_fname_idx_for_now][0]]\n",
    "    \n",
    "    if ( len(list_of_table_version_desc[desc_fname_idx_for_now]) - n_header_lines < n_lines_to_display or\n",
    "         len(list_of_table_version_appl[desc_fname_idx_for_now]) - n_header_lines < n_lines_to_display\n",
    "    ):\n",
    "        n_lines_to_display = min(len(list_of_table_version_desc[desc_fname_idx_for_now]) - n_header_lines,\n",
    "                                 len(list_of_table_version_appl[desc_fname_idx_for_now]) - n_header_lines)\n",
    "    ##endof:  if <n_lines_conditions>\n",
    "    \n",
    "    \n",
    "    for table_idx in range(n_header_lines, \n",
    "                           n_lines_to_display_orig + n_header_lines):\n",
    "        if table_idx - n_header_lines < n_lines_to_display_desc:\n",
    "            display_table_desc.append(list_of_table_version_desc[desc_fname_idx_for_now][table_idx])\n",
    "        ##endof:  if table_idx - n_header_lines < n_lines_to_display_desc\n",
    "        \n",
    "        if table_idx - n_header_lines < n_lines_to_display_appl:\n",
    "            display_table_appl.append(list_of_table_version_appl[desc_fname_idx_for_now][table_idx])\n",
    "        ##endof:  if table_idx - n_header_lines < n_lines_to_display_appl\n",
    "        \n",
    "        display_table_both.append(list_of_table_version_both[0][table_idx])\n",
    "    ##endof:  for idx in range(<n_lines stuff>)\n",
    "    \n",
    "    ####  Dang immutable, pass-by-reference Python stuff. : )\n",
    "    ####+ I'm used to more C-style, but I'm getting better.\n",
    "    deep_display_desc = copy.deepcopy(display_table_desc)\n",
    "    deep_display_appl = copy.deepcopy(display_table_appl)\n",
    "    deep_display_both = copy.deepcopy(display_table_both)\n",
    "    \n",
    "    list_of_display_table_desc.append(deep_display_desc)\n",
    "    list_of_display_table_appl.append(deep_display_appl)\n",
    "    list_of_display_table_both.append(deep_display_both)\n",
    "##endof:  for desc_fname_idx_for_now in range(range(list_of_table_version_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c977a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_dashes = \"--------------------------------------------------------------\"\n",
    "short_dashes = \"-----\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a115016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for desc_fname_idx_for_now in range(len(list_of_display_table_desc)):\n",
    "    print()\n",
    "    print(long_dashes)\n",
    "    print(f\"len(list_of_display_table_desc[{desc_fname_idx_for_now}]):\"+ \\\n",
    "          f\" {len(list_of_table_version_desc[desc_fname_idx_for_now])}\")\n",
    "    print(f\"len(display_table_desc): {len(display_table_desc)}\")\n",
    "    print()\n",
    "    print(f\"len(list_of_display_table_appl[{desc_fname_idx_for_now}]):\" + \\\n",
    "          f\" {len(list_of_display_table_appl[desc_fname_idx_for_now])}\")\n",
    "    print(f\"len(display_table_appl): {len(display_table_appl)}\")\n",
    "    print()\n",
    "    print(f\"len(list_of_display_table_both[{desc_fname_idx_for_now}]):\" + \\\n",
    "          f\" {len(list_of_display_table_both[desc_fname_idx_for_now])}\")\n",
    "    print(f\"len(display_table_both): {len(display_table_both)}\")\n",
    "    print(long_dashes)\n",
    "    print()\n",
    "##endof:  for desc_fname_idx_for_now in range(len(list_of_table_version_desc)):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbaa5eb",
   "metadata": {},
   "source": [
    "Here it comes, the reward for your patience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ae6913",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#import pprint\n",
    "\n",
    "desc_counter = -1 # hack for zero-indexed\n",
    "for this_desc_disp_table in list_of_display_table_desc:\n",
    "    print()\n",
    "    print(long_dashes + short_dashes)\n",
    "    desc_counter += 1\n",
    "    print( \"JOB DESCRIPTION (TOP 25)\")\n",
    "    print(f\"  from file: {local_job_desc_filenames[desc_counter]}\")\n",
    "    print(short_dashes)\n",
    "    #pprint.pprint(display_table_desc)\n",
    "    print_2d_list_columns_aligned(this_desc_disp_table)\n",
    "    print()\n",
    "    print(long_dashes)\n",
    "    print()\n",
    "##endof:  for this_desc_disp_table in list_of_display_table_desc\n",
    "\n",
    "print(long_dashes + 2*short_dashes)\n",
    "print(long_dashes + 2*short_dashes)\n",
    "\n",
    "for this_appl_disp_table in list_of_display_table_appl:\n",
    "    print()\n",
    "    print(long_dashes)\n",
    "    print(\"JOB APPLICATION STUFF - RéSUMé AND COVER LETTER (TOP 25)\")\n",
    "    print(short_dashes)\n",
    "    #pprint.pprint(display_table_appl)\n",
    "    print_2d_list_columns_aligned(this_appl_disp_table)\n",
    "    print()\n",
    "    print(long_dashes)\n",
    "    print()\n",
    "##endof:  for this_appl_disp_table in list_of_display_table_appl\n",
    "\n",
    "print(long_dashes + 2*short_dashes)\n",
    "print(long_dashes + 2*short_dashes)\n",
    "\n",
    "other_desc_counter = -1 # hack for zero-indexed\n",
    "for this_both_disp_table in list_of_display_table_both:\n",
    "    print()\n",
    "    print(long_dashes)\n",
    "    other_desc_counter += 1\n",
    "    print(\"COMPARISON OF DESCRIPTION AND APPLICATION (TOP 25)\")\n",
    "    print(f\"  from file: {local_job_desc_filenames[other_desc_counter]}\")\n",
    "    print(short_dashes)\n",
    "    #pprint.pprint(display_table_both)\n",
    "    print_2d_list_columns_aligned(this_both_disp_table)\n",
    "    print()\n",
    "    print(long_dashes)\n",
    "##endof:  for this_both_disp_table in list_of_table_version_both:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0313a3f6",
   "metadata": {},
   "source": [
    "## Next, in Part 3, We Will Get Words at Different Ranks.\n",
    "\n",
    "### We will also do histograms.\n",
    "\n",
    "### But first, it's pickle time\n",
    "\n",
    "And the link for the Part 2 MyBinder will be included after the pickling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b80b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_filename_2_to_3 = \"important_part_2_vars.pkl\"\n",
    "\n",
    "things_to_pickle_2 = [\n",
    "    local_job_desc_filenames,\n",
    "    local_job_appl_filenames,\n",
    "    list_of_display_table_desc,\n",
    "    list_of_display_table_appl\n",
    "]\n",
    "\n",
    "with open(pickle_filename_2_to_3, 'wb') as pfh:\n",
    "    pickle.dump(things_to_pickle_2, pfh)\n",
    "##endof:  with open ... as pfh # (pickle file handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1158230d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b41410d4",
   "metadata": {},
   "source": [
    "## This is where to copy/paste into Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673bf68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_description_word_at_rank(this_rank = 1, \n",
    "                                 this_desc_fname_idx=0,\n",
    "                                 do_print_details=False\n",
    "                                ):\n",
    "    this_idx = this_rank # the header is index 0\n",
    "    this_table_to_use = \\\n",
    "      list_of_display_table_desc[this_desc_fname_idx]\n",
    "    this_word = this_table_to_use[this_rank][0]\n",
    "    if do_print_details:\n",
    "        print()\n",
    "        print(f\"  The job description word at rank {this_rank},\")\n",
    "        print( \n",
    "          ( \"  from file:\"\n",
    "           f\" '{local_job_desc_filenames[this_desc_fname_idx]}',\"\n",
    "          )\n",
    ")\n",
    "        print(f\"  is '{this_word}'.\")\n",
    "        print()\n",
    "    ##endof: if do_print_details\n",
    "    \n",
    "    return this_word\n",
    "##endof:  get_description_word_at_rank(<params>)\n",
    "\n",
    "def get_application_word_at_rank(this_rank = 1, \n",
    "                                 do_print_details=False\n",
    "                                ):\n",
    "    this_idx = this_rank # the header is index 0\n",
    "    this_appl_fname_idx=0\n",
    "    this_table_to_use = \\\n",
    "      list_of_display_table_appl[this_appl_fname_idx]\n",
    "    this_word = this_table_to_use[this_rank][0]\n",
    "    if do_print_details:\n",
    "        print()\n",
    "        print(f\"  The job application word at rank {this_rank},\")\n",
    "        print( \n",
    "          ( \"  from file:\"\n",
    "           f\" '{local_job_appl_filenames[this_appl_fname_idx]}',\"\n",
    "          )\n",
    ")\n",
    "        print(f\"  is '{this_word}'.\")\n",
    "        print()\n",
    "    ##endof: if do_print_details\n",
    "    \n",
    "    return this_word\n",
    "##endof:  get_description_word_at_rank(<params>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df466e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_description_word_at_rank(1, do_print_details=True);\n",
    "get_application_word_at_rank(1, do_print_details=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db47d24b",
   "metadata": {},
   "source": [
    "## Time for top-25 histograms (or whatever the discretized version is)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca502880",
   "metadata": {},
   "source": [
    "I'm going to go through these histograms one at a time. Basically, I'll compare each of the four job descriptions to my job application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fc230c",
   "metadata": {},
   "source": [
    "### Choices for the job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4a1fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_for_choices = f\"Choices are any of: {list(range(len(local_job_desc_filenames)))}\"\n",
    "print(str_for_choices.replace(r\"[\", r\"{\").replace(r\"]\", r\"}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d15a78e",
   "metadata": {},
   "source": [
    "Output was most recently\n",
    "\n",
    "Choices are any of: `{0, 1, 2, 3}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259d2ea4",
   "metadata": {},
   "source": [
    "### Make your choice in the next cell, if you're pressed for time.\n",
    "\n",
    "Otherwise, you should leave this index as `0`, as it's part of my process of going through all four job descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2359396",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  It's your turn to choose which one you want.\n",
    "##+ Just do this if you are pressed for time and\n",
    "##+ want to see a certain result; I will be displaying\n",
    "##+ all four, here.\n",
    "the_choice_of_description_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dbc3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_idx_00 = the_choice_of_description_index # smaller variable name.\n",
    "the_chosen_filename = local_job_desc_filenames[desc_idx_00]\n",
    "print(f\"We will be looking at: {the_chosen_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08225819",
   "metadata": {},
   "source": [
    "### One value for the job application\n",
    "\n",
    "This is how I want to structure things in general. Even if I have a résumé and a cover letter and a list of skills from the application and whatever questions they want me to answer, I want to combine them. That is possible in one of the functions above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b870b6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  You can't choose a value for now (or it least doing \n",
    "#+ so won't give you anything useful).\n",
    "the_only_application_index_value = 0\n",
    "appl_idx = the_only_application_index_value\n",
    "the_only_application_filename = local_job_appl_filenames[appl_idx]\n",
    "\n",
    "print(f\"And the comparison will be to: {the_only_application_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2186063a",
   "metadata": {},
   "source": [
    "### Code for one histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1847441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "## Next line only for Jupyter notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "def get_histo_from_freq_dict(word_count_ordered_dict,\n",
    "                             n_top_words = 25,\n",
    "                             do_show_frac_not_count=False,\n",
    "                             do_show_wd_cnt_or_frac_lists=False,\n",
    "                             axx=None\n",
    "                            ):\n",
    "    '''\n",
    "    @return  an axis from matplotlab (with the object - histogram - in it)\n",
    "    '''\n",
    "    \n",
    "    if axx is None:\n",
    "        fig = plt.figure(figsize=(10, 3))\n",
    "        axx = fig.add_subplot(111)\n",
    "    ##endof:  if axx is None\n",
    "    \n",
    "    counts = None\n",
    "    fractions = None\n",
    "    \n",
    "    if do_show_frac_not_count:\n",
    "        #frac_wd_cnt_ordered_dict = copy.deep_copy(word_count_ordered_dict) \n",
    "        frac_wd_cnt_list_of_tuples = \\\n",
    "          [ ( k, (v / len(word_count_ordered_dict)) )\n",
    "                  for k, v in word_count_ordered_dict.items()]\n",
    "        fractions_pre = [ this_item[1] \n",
    "                           for this_item in frac_wd_cnt_list_of_tuples ]\n",
    "        \n",
    "        #fractions_pre = list(frac_wd_cnt_ordered_dict.values())\n",
    "        fractions = fractions_pre[:n_top_words]\n",
    "    else:\n",
    "        counts_pre = list(word_count_ordered_dict.values())\n",
    "        counts = counts_pre[:n_top_words]\n",
    "    ##endof:  if/else do_show_frac_not_count\n",
    "    \n",
    "    words_pre  = list(word_count_ordered_dict.keys())\n",
    "    words  = words_pre[:n_top_words]\n",
    "    \n",
    "    ## making sure things were working\n",
    "    if do_show_wd_cnt_or_frac_lists:\n",
    "        if do_show_frac_not_count:\n",
    "            print (f\"fractions: {fractions}\")\n",
    "        else:\n",
    "            print(f\"counts: {counts}\")\n",
    "        ##endof:  if do_show_frac_not_count\n",
    "        print(f\"words:  {words}\")\n",
    "    ##endof:  if do_show_word_and_count_lists\n",
    "    \n",
    "    x_words_coords = np.arange(len(words))\n",
    "    \n",
    "    if do_show_frac_not_count:\n",
    "        axx.bar(x_words_coords, fractions, align='center')\n",
    "    else:\n",
    "        axx.bar(x_words_coords, counts, align='center')\n",
    "    ##endof:  if/else do_show_frac_not_count\n",
    "    \n",
    "    axx.set_xticks(x_words_coords)\n",
    "    axx.set_xticklabels(words, rotation=45, ha='right')\n",
    "    \n",
    "##endof:  get_histo_from_freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eef44ce",
   "metadata": {},
   "source": [
    "### Let's see a histogram for the job description with word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d223537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_histo_from_freq_dict(description_word_counts[desc_idx_00],\n",
    "                         do_show_wd_cnt_or_frac_lists=True)\n",
    "\n",
    "desc_top_25_hist_fname = \"top_25_application_words.png\"\n",
    "plt.savefig(desc_top_25_hist_fname,\n",
    "            bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1c0ec9",
   "metadata": {},
   "source": [
    "### Now, let's see one for the job description with word frequency as a fraction of total words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e23d64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_histo_from_freq_dict(description_word_counts[desc_idx_00],\n",
    "                         do_show_frac_not_count=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b047b4",
   "metadata": {},
   "source": [
    "### Here comes the histogram for the job application with word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6195381",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_histo_from_freq_dict(application_word_counts[appl_idx],\n",
    "                         do_show_wd_cnt_or_frac_lists=True)\n",
    "\n",
    "appl_top_25_hist_fname = \"top_25_application_words.png\"\n",
    "plt.savefig(appl_top_25_hist_fname,\n",
    "            bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6e897d",
   "metadata": {},
   "source": [
    "### And the histogram for the job application  with word frequency as a fraction of total words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a916bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_histo_from_freq_dict(application_word_counts[appl_idx],\n",
    "                         do_show_frac_not_count=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b5c149",
   "metadata": {},
   "source": [
    "### Change the img src values and img alt values, then see the histograms together\n",
    "\n",
    "You might need to double-click on the image to get the html source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7b313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"  img src values for the two images:\")\n",
    "print(f'\"{desc_top_25_hist_fname}\"')\n",
    "print(f'\"{appl_top_25_hist_fname}\"')\n",
    "\n",
    "print()\n",
    "print(\"  img alt values for the two images:\")\n",
    "wd_count_alt_text_1 = '\"The histogram for the job description with word frequencies\"'\n",
    "wd_count_alt_text_2 = '\"The histogram for the job application with word frequencies\"'\n",
    "\n",
    "print(wd_count_alt_text_1)\n",
    "print(wd_count_alt_text_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa4275d",
   "metadata": {},
   "source": [
    "The output histograms, stacked for easier view.\n",
    "\n",
    "_Remember that you might need to double click on the images to change the img src and img alt values._\n",
    "\n",
    "<br/>\n",
    "<div>\n",
    "  <img src=\"top_25_description_words.png\"\n",
    "       alt=\"The histogram for the job description with word frequencies\"\n",
    "       width=\"auto\">\n",
    "</div>\n",
    "<br/>\n",
    "\n",
    "<br/>\n",
    "<div>\n",
    "  <img src=\"top_25_application_words.png\"\n",
    "       alt=\"The histogram for the job application with word frequencies\"\n",
    "       width=\"auto\">\n",
    "</div>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608b547f",
   "metadata": {},
   "source": [
    "Sometimes, I'll grab a printscreen of the above two images and draw green lines between words that match. However, from the time when I allowed the view of the match and three surrounding words, this step hasn't seemed as vital.\n",
    "\n",
    "If this is going to happen, double click on this cell to see the now-commented HTML, get your saved filename, change the HTML accordingly, and uncomment everything. (HTML Comments start with `<!--` and end with `-->`\n",
    "\n",
    "<!--\n",
    "<br/>\n",
    "<div>\n",
    "  <img src=\"word_frequency_plots_w_link_lines.jpg\"\n",
    "       alt=\"Word matches for the pair of histograms.\"\n",
    "       width=\"100%\">\n",
    "</div>\n",
    "<br/>\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ab4fd2",
   "metadata": {},
   "source": [
    "## A better way to compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a832f5e7",
   "metadata": {},
   "source": [
    "### Seems like a good time to look at comparisons\n",
    "\n",
    "#### Between the résumé and the different job descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300922dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word_in_both_display_lists(word_to_find,\n",
    "                                    display_list_1_description,\n",
    "                                    display_list_2_application,\n",
    "                                    name_of_display_list_1=None,\n",
    "                                    name_of_display_list_2=None,\n",
    "                                    do_print_details=False\n",
    "                                   ):\n",
    "    index_count_1 = 0 # skip header\n",
    "    index_for_found_in_1 = 0\n",
    "    \n",
    "    loop_display_list = display_list_1_description\n",
    "    \n",
    "    word_found_in_1 = False\n",
    "    for my_entry_1 in display_list_1_description:\n",
    "        index_count_1 += 1\n",
    "        if my_entry_1 == word_to_find:\n",
    "            word_found_in_1 = True\n",
    "            index_for_found_in_1 = index_count_1\n",
    "            break\n",
    "        ##endof:  if my_entry_1 == word_to_find\n",
    "    ##endof:  for my_entry_1 in display_list_1\n",
    "    \n",
    "    index_count_2 = 0 # skip header\n",
    "    index_for_found_in_2 = -1\n",
    "    word_found_in_2 = False\n",
    "    for my_entry_2 in display_list_2_application:\n",
    "        index_count_2 += 1\n",
    "        if my_entry_2 == word_to_find:\n",
    "            word_found_in_2 = True\n",
    "            index_for_found_in_2 = index_count_2\n",
    "            break\n",
    "        ##endof:  if my_entry_2 == word_to_find\n",
    "    ##endof:  for my_entry_1 in display_list_1\n",
    "    \n",
    "    to_return_found_1 = None\n",
    "    \n",
    "    if word_found_in_1:\n",
    "        to_return_found_1 = index_for_found_in_1 # - 1\n",
    "        if do_print_details:\n",
    "            print()\n",
    "            print(f\"The word, {word_to_find}, has rank, {to_return_found_1},\")\n",
    "            if name_of_display_list_1 is not None:\n",
    "                print(f\"in list, {name_of_display_list_1}.\")\n",
    "            #endof:  if name_of_display_list_1 is not None\n",
    "        ##endof:  if do_print_details\n",
    "    ##endof:  if word_found_in_1\n",
    "    \n",
    "    to_return_found_2 = None\n",
    "    \n",
    "    if word_found_in_2:\n",
    "        to_return_found_2 = index_for_found_in_2 # - 1\n",
    "        if do_print_details:\n",
    "            print()\n",
    "            print(f\"The word, {word_to_find}, has rank, {to_return_found_2},\")\n",
    "            if name_of_display_list_2 is not None:\n",
    "                print(f\"in list, {name_of_display_list_2}.\")\n",
    "            ##endof:  if name_of_display_list_2 is not None\n",
    "        ##endof:  if do_print_details\n",
    "    ##endof:  if word_found_in_2\n",
    "    \n",
    "    return to_return_found_1, to_return_found_2\n",
    "    \n",
    "##endof:  find_word_in_both_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2590f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Next line only for Jupyter notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "def get_freq_histo_specific(word_count_ordered_dict_1,\n",
    "#                           word_count_ordered_dict_2,\n",
    "                            rank_index_1 = 1,\n",
    "                            n_surrounding_words = 3,\n",
    "                            do_show_word_and_count_lists=False,\n",
    "                            ax1=None,\n",
    "#                           ,ax2=None\n",
    "                            ylim_bottom_val=None,\n",
    "                            ylim_top_val=None\n",
    "                           ):\n",
    "    '''\n",
    "    @return  an axis from matplotlab (with the object - histogram - in it)\n",
    "    '''\n",
    "    \n",
    "    if ax1 is None:\n",
    "        fig = plt.figure(figsize=(10, 3))\n",
    "        ax1 = fig.add_subplot(111)\n",
    "#       ax2 = fig.add_subplot(121)\n",
    "    ##endof:  if ax1 is None\n",
    "    \n",
    "    counts_pre = list(word_count_ordered_dict_1.values())\n",
    "    words_pre  = list(word_count_ordered_dict_1.keys())\n",
    "    \n",
    "    #word_1, count_1 = word_count_ordered_dict_1[rank_index_1]\n",
    "    \n",
    "    #highest_rank_index = -1\n",
    "    \n",
    "    # Pad the list with zero-count and empty-set characters\n",
    "    len_lists = 2 * n_surrounding_words + 1\n",
    "    counts = [0] * len_lists\n",
    "    words  = [\"\\u2205\"] * len_lists\n",
    "    \n",
    "    #  Fill anything with a valid index with the corresponding\n",
    "    #+ word/count\n",
    "    \n",
    "    current_output_index = -1\n",
    "    \n",
    "    for i in range(rank_index_1 - n_surrounding_words -1,\n",
    "                   rank_index_1 + n_surrounding_words\n",
    "                  ):\n",
    "        current_output_index += 1\n",
    "        if i < 0:\n",
    "            pass\n",
    "        else:\n",
    "            counts[current_output_index] = counts_pre[i]\n",
    "            words[current_output_index] = words_pre[i]\n",
    "        ##endof:  if/else i < 1\n",
    "    ##endof:  for i in range\n",
    "    \n",
    "    ## making sure things are working\n",
    "    if do_show_word_and_count_lists:\n",
    "        print(f\"counts: {counts}\")\n",
    "        print(f\"words:  {words}\")\n",
    "    ##endof:  if do_show_word_and_count_lists\n",
    "    \n",
    "    #input(\"Press [Enter] to continue.\")\n",
    "    \n",
    "    x_words_coords = np.arange(len(words))\n",
    "    ax1.bar(x_words_coords, counts, align='center')\n",
    "    \n",
    "    ax1.set_xticks(x_words_coords)\n",
    "    ax1.set_xticklabels(words, rotation=45, ha='right')\n",
    "    \n",
    "    ax1.set_ylim(ylim_bottom_val, ylim_top_val)\n",
    "    \n",
    "##endof:  get_freq_histo_specific"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fe1780",
   "metadata": {},
   "source": [
    "<strike>Below will be code to look for the top 25 (maybe less, maybe more) description words. I'll go through every word that appears 3 times, and I won't include any that appear only twice or once. I'll see where they appear in my résumé list.</strike>\n",
    "\n",
    "<strike>This will be easily automated and done with a for loop or list comprehension. However, I want to look at some things more manually - that should make the automated stuff better.</strike>\n",
    "\n",
    "I'm going to make this part more of a look-for-each-word thing. The display is too busy to show each word for each file.\n",
    "\n",
    "I have a few improvements that would be good, soon:<br/>\n",
    "  @TODO : get rid of one letter words<br/>\n",
    "  @TODO : look through the rest of the list to get rid of junk\n",
    "\n",
    "I want to match two histograms for this stuff, with e.g. the job description's word and (up to) 3 (or 4 or 5 or 6 or 2 or 1 or ...) words more frequent and (up to) 3 words less frequent. I'm going to bring up a picture of the histograms for my brainstorming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80d1403",
   "metadata": {},
   "source": [
    "### Here are the specific word-rank comparison histograms..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc3071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_for_choices = f\"Choices are any of: {list(range(len(local_job_desc_filenames)))}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04621fa6",
   "metadata": {},
   "source": [
    "####  For this section, we have calculated everything, but show just two files being compared\n",
    "\n",
    "Well, when we get to the compare-all-top-25 histograms, we'll show all the comparisons.\n",
    "\n",
    "For the comparisons of the top-ranked words, just two files at a time\n",
    "\n",
    "Another thing, to keep this Quick and Reckless (not spending too much time), I'm dispensing with my cherished 80 characters per line. `: (`\n",
    "\n",
    "**You can change the `desc_fname_idx_to_show` to any of the numbers in the next output ...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337c1a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str_for_choices.replace(r\"[\", r\"{\").replace(r\"]\", r\"}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80631c39",
   "metadata": {},
   "source": [
    "Output was most recently\n",
    "\n",
    "Choices are any of: `{0, 1, 2, 3}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4573c2",
   "metadata": {},
   "source": [
    "... **to see results for a specific job description.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab896776",
   "metadata": {},
   "outputs": [],
   "source": [
    "for my_desc_index in range(len(local_job_desc_filenames)):\n",
    "    print(f\"Choice {my_desc_index} : {local_job_desc_filenames[my_desc_index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba3985d",
   "metadata": {},
   "source": [
    "### ... for your choice of job description and word/word rank\n",
    "\n",
    "(rank in the job description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24993050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make your choice:\n",
    "desc_fname_idx_to_show = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f7f2d1",
   "metadata": {},
   "source": [
    "### Now we can continue with the top-ranked word in the job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f472c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_word_rank_in_desc = 1\n",
    "this_corresponding_word = get_description_word_at_rank(top_word_rank_in_desc)\n",
    "this_desc_idx = desc_fname_idx_to_show\n",
    "word_indexes = find_word_in_both_display_lists(\n",
    "                 this_corresponding_word,\n",
    "                 description_word_counts[desc_fname_idx_to_show],\n",
    "                 application_word_counts[0],\n",
    "                   #  we only have one table - \n",
    "                   #+ it's at any legal index;\n",
    "                   #+ let's choose 0\n",
    "                 name_of_display_list_1 = f\"description_word_counts[{this_desc_idx}]\",\n",
    "                 name_of_display_list_2 = \"application_word_counts[0]\"                \n",
    ")\n",
    "\n",
    "print()\n",
    "print( (\"(rank in description, rank in application) for the word,\"\n",
    "        f\" '{this_corresponding_word}': {word_indexes}\"\n",
    "       )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b257f482",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top_word_rank_in_desc = 1\n",
    "this_desc_idx = top_word_rank_in_desc\n",
    "\n",
    "this_corresponding_word = get_description_word_at_rank(top_word_rank_in_desc)\n",
    "\n",
    "print(f\"this_corresponding_word: {this_corresponding_word}\")\n",
    "\n",
    "rank_desc, _ = find_word_in_both_display_lists(\n",
    "                this_corresponding_word,\n",
    "                description_word_counts[desc_fname_idx_to_show],\n",
    "                application_word_counts[0],\n",
    "                   #  we only have one table - \n",
    "                   #+ it's at any legal index;\n",
    "                   #+ let's choose 0\n",
    "                name_of_display_list_1 = f\"description_word_counts[{this_desc_idx}]\",\n",
    "                name_of_display_list_2 = \"application_word_counts[0]\"\n",
    ")\n",
    "\n",
    "fig_filename_desc = \"\"\n",
    "\n",
    "if rank_desc is None:\n",
    "    import matplotlib.image as mpimg\n",
    "    fig_filename_desc = \"description_word_not_found.png\"\n",
    "    img = mpimg.imread(fig_filename_desc)\n",
    "    imgplot = plt.imshow(img)\n",
    "##endof:  if rank_desc\n",
    "else:\n",
    "    get_freq_histo_specific(\n",
    "            description_word_counts[desc_fname_idx_to_show],\n",
    "            rank_index_1=this_desc_idx,\n",
    "            n_surrounding_words=3,\n",
    "            do_show_word_and_count_lists=False,\n",
    "            ylim_top_val=12)\n",
    "    \n",
    "    fig_filename_desc = (\n",
    "            f\"description_word_rank_{this_desc_idx}_\"\n",
    "            f\"desc_{desc_fname_idx_to_show}.png\"\n",
    "    )\n",
    "    \n",
    "    print(fig_filename_desc)\n",
    "\n",
    "    title_for_desc = (f\"Word frequency rank ({rank_desc}) and surrounding context in \"\n",
    "                      f\"job description for the word, {this_corresponding_word}\"\n",
    "                 )\n",
    "    plt.title(title_for_desc)\n",
    "\n",
    "    plt.savefig(fig_filename_desc,\n",
    "                bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "##endof:  if/else rank_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340abb8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_, rank_appl = find_word_in_both_display_lists(\n",
    "        this_corresponding_word,\n",
    "        description_word_counts[desc_fname_idx_to_show],\n",
    "        application_word_counts[0],\n",
    "           #  we only have one table - \n",
    "           #+ it's at any legal index;\n",
    "           #+ let's choose 0\n",
    "        name_of_display_list_1 = f\"description_word_counts[{this_desc_idx}]\",\n",
    "        name_of_display_list_2 = \"application_word_counts[0]\"\n",
    ")\n",
    "\n",
    "fig_filename_appl = \"\"\n",
    "\n",
    "if rank_appl is None:\n",
    "    import matplotlib.image as mpimg\n",
    "    fig_filename_appl = \"application_word_not_found.png\"\n",
    "    img = mpimg.imread(fig_filename_appl)\n",
    "    imgplot = plt.imshow(img)\n",
    "##endof:  if rank_desc\n",
    "else:\n",
    "    corresponding_index = rank_appl\n",
    "    \n",
    "    get_freq_histo_specific(application_word_counts[0],\n",
    "                        rank_index_1=corresponding_index,\n",
    "                        n_surrounding_words=3,\n",
    "                        do_show_word_and_count_lists=False,\n",
    "                        ylim_top_val=12)\n",
    "\n",
    "    fig_filename_appl = (f\"application_word_rank_{corresponding_index}_\"\n",
    "                         f\"desc_{desc_fname_idx_to_show}.png\"\n",
    "                        )\n",
    "\n",
    "    title_for_appl = (f\"Word frequency rank ({rank_appl}) and surrounding context in \"\n",
    "                      f\"job application for the word, {this_corresponding_word}\"\n",
    "                     )\n",
    "    plt.title(title_for_appl)\n",
    "\n",
    "    plt.savefig(fig_filename_appl,\n",
    "            bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "##endof:  ##endof:  if/else rank_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ada010",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"  img src values for the two images:\")\n",
    "print(f'\"{fig_filename_desc}\"')\n",
    "print(f'\"{fig_filename_appl}\"')\n",
    "\n",
    "print()\n",
    "print(\"  img alt values for the two images:\")\n",
    "alt_text_1 = (f'\"Histogram for the word, {this_corresponding_word}, in '\n",
    "               'the job description text\"'\n",
    "             )\n",
    "alt_text_2 = (f'\"Histogram for the word, {this_corresponding_word}, in '\n",
    "               'the job application text\"'\n",
    "             )\n",
    "print(alt_text_1)\n",
    "print(alt_text_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a127c5",
   "metadata": {},
   "source": [
    "### Change the img src values and img alt values, then see the histograms together\n",
    "\n",
    "You might need to double-click on the image to get the html source.\n",
    "\n",
    "<br/>\n",
    "<div>\n",
    "  <img src=\"description_word_rank_1_desc_0.png\"\n",
    "       alt=\"Histogram for the word, software, in the job description text\"\n",
    "       width=\"auto\">\n",
    "</div>\n",
    "<br/>\n",
    "\n",
    "<br/>\n",
    "<div>\n",
    "  <img src=\"application_word_rank_2_desc_0.png\"\n",
    "       alt=\"Histogram for the word, software, in the job application text\"\n",
    "       width=\"auto\">\n",
    "</div>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e098db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Code to look for the top 25 (probably more) application\n",
    "#+ (résumé) words (down to appearing 3 times -- not\n",
    "#+ including 2) and see where they appear in the job\n",
    "#+ descriptions (if at all.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d482669e",
   "metadata": {},
   "source": [
    "## Time for top-25 histograms (or whatever the discretized version is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5092550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Next line only for Jupyter notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "def get_histo_from_freq_dict(word_count_ordered_dict,\n",
    "                             n_top_words = 25,\n",
    "                             do_show_word_and_count_lists=False,\n",
    "                             axx=None\n",
    "                            ):\n",
    "    '''\n",
    "    @return  an axis from matplotlab (with the object - histogram - in it)\n",
    "    '''\n",
    "    \n",
    "    if axx is None:\n",
    "        fig = plt.figure(figsize=(10, 3))\n",
    "        axx = fig.add_subplot(111)\n",
    "    \n",
    "    counts_pre = list(word_count_ordered_dict.values())\n",
    "    words_pre  = list(word_count_ordered_dict.keys())\n",
    "    \n",
    "    counts = counts_pre[:n_top_words]\n",
    "    words  = words_pre[:n_top_words]\n",
    "    \n",
    "    ## making sure things were working\n",
    "    if do_show_word_and_count_lists:\n",
    "        print(f\"counts: {counts}\")\n",
    "        print(f\"words:  {words}\")\n",
    "    ##endof:  if do_show_word_and_count_lists\n",
    "    \n",
    "    x_words_coords = np.arange(len(words))\n",
    "    axx.bar(x_words_coords, counts, align='center')\n",
    "    \n",
    "    axx.set_xticks(x_words_coords)\n",
    "    axx.set_xticklabels(words, rotation=45, ha='right')\n",
    "    \n",
    "##endof:  get_histo_from_freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b6f8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_histo_from_freq_dict(description_word_counts[desc_fname_idx_to_show], \n",
    "                         do_show_word_and_count_lists=True)\n",
    "\n",
    "desc_top_25_hist_fname = \"top_25_description_words.png\"\n",
    "plt.savefig(desc_top_25_hist_fname,\n",
    "            bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c005d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_histo_from_freq_dict(application_word_counts[0],\n",
    "                         do_show_word_and_count_lists=True)\n",
    "\n",
    "appl_top_25_hist_fname = \"top_25_application_words.png\"\n",
    "plt.savefig(appl_top_25_hist_fname,\n",
    "            bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf7ae60",
   "metadata": {},
   "source": [
    "## Output for Description and Application:\n",
    "\n",
    "### &lt;FILL THIS IN&gt;\n",
    "\n",
    "### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c55c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #######################\n",
    "# # No need to run again\n",
    "# #####\n",
    "!powershell -c (Get-Date -UFormat \"%s_%Y%m%dT%H%M%S%Z00\") -replace '[.][0-9]*_', '_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1acab5",
   "metadata": {},
   "source": [
    "The output when I actually did this was\n",
    "\n",
    "```\n",
    "1692569216_20230820T220656-0600\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd2eff7",
   "metadata": {},
   "source": [
    "### Change the img src values and img alt values, then see the histograms together\n",
    "\n",
    "You might need to double-click on the image to get the html source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e670a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"  img src values for the two images:\")\n",
    "print(f'\"{desc_top_25_hist_fname}\"')\n",
    "print(f'\"{appl_top_25_hist_fname}\"')\n",
    "\n",
    "print()\n",
    "print(\"  img alt values for the two images:\")\n",
    "wd_count_alt_text_1 = '\"The histogram for the job description with word frequencies\"'\n",
    "wd_count_alt_text_2 = '\"The histogram for the job application with word frequencies\"'\n",
    "\n",
    "print(wd_count_alt_text_1)\n",
    "print(wd_count_alt_text_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d31453",
   "metadata": {},
   "source": [
    "The output histograms, stacked for easier view.\n",
    "\n",
    "_Remember that you might need to double click on the images to change the img src and img alt values._\n",
    "\n",
    "<br/>\n",
    "<div>\n",
    "  <img src=\"top_25_description_words.png\"\n",
    "       alt=\"The histogram for the job description with word frequencies\"\n",
    "       width=\"auto\">\n",
    "</div>\n",
    "<br/>\n",
    "\n",
    "<br/>\n",
    "<div>\n",
    "  <img src=\"top_25_application_words.png\"\n",
    "       alt=\"The histogram for the job application with word frequencies\"\n",
    "       width=\"auto\">\n",
    "</div>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecf6cde",
   "metadata": {},
   "source": [
    "Sometimes, I'll grab a printscreen of the above two images and draw green lines between words that match. However, from the time when I allowed the view of the match and three surrounding words, this step hasn't seemed as vital.\n",
    "\n",
    "If this is going to happen, double click on this cell to see the now-commented HTML, get your saved filename, change the HTML accordingly, and uncomment everything. (HTML Comments start with `<!--` and end with `-->`\n",
    "\n",
    "<!--\n",
    "<br/>\n",
    "<div>\n",
    "  <img src=\"word_frequency_plots_w_link_lines.jpg\"\n",
    "       alt=\"Word matches for the pair of histograms.\"\n",
    "       width=\"100%\">\n",
    "</div>\n",
    "<br/>\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e01967",
   "metadata": {},
   "source": [
    "## Future Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779b13da",
   "metadata": {},
   "source": [
    "- Look at ranking, counts, percentage, etc. for FamilySearch's (job description's) top 25 words as found in my (job application's) word counts, then vice-versa. \n",
    "  - Code setup completed 2023-08-20. Putting all 25 in would make a very busy display, so I just did a few.\n",
    "- Get rid of words that are necessary for grammar, but which don't matter too much in determining whether the two documents match up. (Found term on 2023-08-07. It's \"stopwords\".)\n",
    "  - Completed 2023-08-09"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e7f734",
   "metadata": {},
   "source": [
    "**Some new future steps**\n",
    "\n",
    "- Do word counts for the pair of top 25, but then also do the fraction each word comprises of the whole (non-stopword) text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d73f0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
