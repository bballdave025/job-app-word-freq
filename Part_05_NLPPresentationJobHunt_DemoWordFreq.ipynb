{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02d10fc3",
   "metadata": {},
   "source": [
    "# Job-Hunt NLP Demo - Part 5\n",
    "\n",
    "Which demo will also be useful in doing some quick NLP work to see how my résumé's word distribution matches that from job descriptions.\n",
    "\n",
    "There's a wonderful project out there, [MyBinder](https://mybinder.org), which allows you to interactively run a Jupyter notebook completely online. It's nice to have when you'd like to play with code and see better the outputs that come from running that code. I've had some problems with images going down, but I'm going to work to keep this one up.\n",
    "\n",
    "The link to the online, interactive notebook - the binder - is at the badge you see right here\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/bballdave025/job-app-word-freq/main?labpath=Part_04_NLPPresentationJobHunt_DemoWordFreq.ipynb)\n",
    "\n",
    "<hr/>\n",
    "\n",
    "## We are calling this version 0.1.003\n",
    "\n",
    "It's the FamilySearch CJKV jobs applied for in August 2023, but we're splitting it into smaller notebooks. Hopefully, MyBinder can load each more quickly. We'll see how things work with pickling variables between the parts.\n",
    "\n",
    "**Edit:** It worked pretty well.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "## What we are doing in Part 5\n",
    "\n",
    "First of all, let's give you a MyBinder badge link which specifies the version and the part.\n",
    "\n",
    "[![Binder](./badge_logo_dwb_v_0-1-003_part_5.png)](https://mybinder.org/v2/gh/bballdave025/job-app-word-freq/main?labpath=Part_05_NLPPresentationJobHunt_DemoWordFreq.ipynb)\n",
    "\n",
    "@TODO : put a few whatchamacallits about what we're doing in Part 5.\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbd5a12",
   "metadata": {},
   "source": [
    "## Let's start by un-pickle-ing the things we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae198da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_filename_4_to_5 = \"important_part_4_vars.pkl\"\n",
    "\n",
    "unpickled_array = []\n",
    "\n",
    "with open(pickle_filename_4_to_5, 'rb') as pfh:\n",
    "    unpickled_array = pickle.load(pfh)\n",
    "##endof:  with open ... as pfh # (pickle file handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b80b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_job_desc_filenames = unpickled_array[0]\n",
    "local_job_appl_filenames = unpickled_array[1]\n",
    "description_word_counts = unpickled_array[2]\n",
    "application_word_counts = unpickled_array[3]\n",
    "list_of_display_table_desc = unpickled_array[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41410d4",
   "metadata": {},
   "source": [
    "## Details for All 25 Top Words (Both documents) and Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b865afb",
   "metadata": {},
   "source": [
    "### First, a review of where we've been @TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ac3a13",
   "metadata": {},
   "source": [
    "@TODO Review what we've done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff19c1b",
   "metadata": {},
   "source": [
    "Good things are what we've done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e373b5d",
   "metadata": {},
   "source": [
    "From our previous stuff, there are some nice functions that we're just copying and pasting, because it seems transferring functions via pickle file is a nightmare. A lot of them are shorter, without the `print_details` types of parameters. We've already seen these, so feel free to <kbd>Shift</kbd> + <kbd>Enter</kbd> your way through the functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bafdab",
   "metadata": {},
   "source": [
    "## Previous functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2ec6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_description_word_at_rank(this_rank = 1, \n",
    "                                 this_desc_fname_idx=0\n",
    "                                ):\n",
    "    this_idx = this_rank # the header is index 0\n",
    "    this_table_to_use = \\\n",
    "      list_of_display_table_desc[this_desc_fname_idx]\n",
    "    this_word = this_table_to_use[this_rank][0]\n",
    "        \n",
    "    return this_word\n",
    "##endof:  get_description_word_at_rank(<params>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bd2dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_application_word_at_rank(this_rank = 1):\n",
    "    this_idx = this_rank # the header is index 0\n",
    "    this_appl_fname_idx=0\n",
    "    this_table_to_use = \\\n",
    "      list_of_display_table_appl[this_appl_fname_idx]\n",
    "    this_word = this_table_to_use[this_rank][0]\n",
    "    \n",
    "    return this_word\n",
    "##endof:  get_description_word_at_rank(<params>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd33e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word_in_both_display_lists(word_to_find,\n",
    "                                    display_list_1_description,\n",
    "                                    display_list_2_application,\n",
    "                                    name_of_display_list_1=None,\n",
    "                                    name_of_display_list_2=None,\n",
    "                                   ):\n",
    "    index_count_1 = 0 # skip header\n",
    "    index_for_found_in_1 = 0\n",
    "    \n",
    "    word_found_in_1 = False\n",
    "    for my_entry_1 in display_list_1_description:\n",
    "        index_count_1 += 1\n",
    "        if my_entry_1 == word_to_find:\n",
    "            word_found_in_1 = True\n",
    "            index_for_found_in_1 = index_count_1\n",
    "            break\n",
    "        ##endof:  if my_entry_1 == word_to_find\n",
    "    ##endof:  for my_entry_1 in display_list_1\n",
    "    \n",
    "    index_count_2 = 0 # skip header\n",
    "    index_for_found_in_2 = -1\n",
    "    word_found_in_2 = False\n",
    "    for my_entry_2 in display_list_2_application:\n",
    "        index_count_2 += 1\n",
    "        if my_entry_2 == word_to_find:\n",
    "            word_found_in_2 = True\n",
    "            index_for_found_in_2 = index_count_2\n",
    "            break\n",
    "        ##endof:  if my_entry_2 == word_to_find\n",
    "    ##endof:  for my_entry_1 in display_list_1\n",
    "    \n",
    "    to_return_found_1 = None\n",
    "    \n",
    "    if word_found_in_1:\n",
    "        to_return_found_1 = index_for_found_in_1 # - 1\n",
    "    ##endof:  if word_found_in_1\n",
    "    \n",
    "    to_return_found_2 = None\n",
    "    \n",
    "    if word_found_in_2:\n",
    "        to_return_found_2 = index_for_found_in_2 # - 1\n",
    "    ##endof:  if word_found_in_2\n",
    "    \n",
    "    return to_return_found_1, to_return_found_2\n",
    "    \n",
    "##endof:  find_word_in_both_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e7a83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Next line only for Jupyter notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "def get_freq_histo_specific(word_count_ordered_dict_1,\n",
    "                            rank_index_1 = 1,\n",
    "                            n_surrounding_words = 3,\n",
    "                            do_show_frac_not_count=True,\n",
    "                            ylim_bottom_val=None,\n",
    "                            ylim_top_val=None,\n",
    "                            ax1=None,\n",
    "                            do_show_word_and_count_lists=False,\n",
    "                           ):\n",
    "    '''\n",
    "    @return  an axis from matplotlab (with the object - histogram - in it)\n",
    "    '''\n",
    "    \n",
    "    if ax1 is None:\n",
    "        fig = plt.figure(figsize=(10, 3))\n",
    "        ax1 = fig.add_subplot(111)\n",
    "    ##endof:  if ax1 is None\n",
    "    \n",
    "    counts_pre = None\n",
    "    fractions_pre = None\n",
    "    \n",
    "    if do_show_frac_not_count:\n",
    "        frac_wd_cnt_list_of_tuples = \\\n",
    "          [ ( k, (v / len(word_count_ordered_dict_1)) )\n",
    "                  for k, v in word_count_ordered_dict_1.items() ]\n",
    "        fractions_pre = [ this_item[1]\n",
    "                           for this_item in frac_wd_cnt_list_of_tuples ]\n",
    "    else:\n",
    "        counts_pre = list(word_count_ordered_dict_1.values())\n",
    "    ##endof:  if/else do_show_frac_not_count\n",
    "    \n",
    "    words_pre  = list(word_count_ordered_dict_1.keys())\n",
    "    \n",
    "    counts = None\n",
    "    fractions = None\n",
    "    \n",
    "    # Pad the list with zero-count and empty-set characters\n",
    "    len_lists = 2 * n_surrounding_words + 1\n",
    "    \n",
    "    if do_show_frac_not_count:\n",
    "        fractions = [0] * len_lists\n",
    "    else:\n",
    "        counts = [0] * len_lists\n",
    "    ##endof:  if/else do_show_frac_not_count\n",
    "    \n",
    "    words  = [\"\\u2205\"] * len_lists # empty-set glyph codepoint\n",
    "    \n",
    "    #  Fill anything with a valid index with the corresponding\n",
    "    #+ word/count\n",
    "    \n",
    "    current_output_index = -1\n",
    "    \n",
    "    for i in range(rank_index_1 - n_surrounding_words -1,\n",
    "                   rank_index_1 + n_surrounding_words\n",
    "                  ):\n",
    "        current_output_index += 1\n",
    "        if i < 0:\n",
    "            pass\n",
    "        else:\n",
    "            if do_show_frac_not_count:\n",
    "                fractions[current_output_index] = fractions_pre[i]\n",
    "            else:\n",
    "                counts[current_output_index] = counts_pre[i]\n",
    "            ##endof:  if/else do_show_frac_not_count\n",
    "            \n",
    "            words[current_output_index] = words_pre[i]\n",
    "        ##endof:  if/else i < 1\n",
    "    ##endof:  for i in range\n",
    "    \n",
    "    ## the text version of the info\n",
    "    if do_show_word_and_count_lists:\n",
    "        if do_show_frac_not_count:\n",
    "            print(f\"fractions: {fractions}\")\n",
    "        else:\n",
    "            print(f\"counts: {counts}\")\n",
    "        ##endof:  if/else do_show_frac_not_count\n",
    "        \n",
    "        print(f\"words:  {words}\")\n",
    "    ##endof:  if do_show_word_and_count_lists\n",
    "    \n",
    "    x_words_coords = np.arange(len(words))\n",
    "    \n",
    "    if do_show_frac_not_count:\n",
    "        ax1.bar(x_words_coords, fractions, align='center')\n",
    "    else:\n",
    "        ax1.bar(x_words_coords, counts, align='center')\n",
    "    ##endof:  if/else do_show_frac_not_count\n",
    "    \n",
    "    ax1.set_xticks(x_words_coords)\n",
    "    ax1.set_xticklabels(words, rotation=45, ha='right')\n",
    "    \n",
    "    ax1.set_ylim(ylim_bottom_val, ylim_top_val)\n",
    "    \n",
    "##endof:  get_freq_histo_specific"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ab4fd2",
   "metadata": {},
   "source": [
    "## End of Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab378cb",
   "metadata": {},
   "source": [
    "### Stop the <kbd>Shift</kbd> + <kbd>Enter</kbd> Madness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2989845",
   "metadata": {},
   "source": [
    "# STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1270e8d",
   "metadata": {},
   "source": [
    "## The functions are Loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8658e42e",
   "metadata": {},
   "source": [
    "## We are at a place you probably want to see"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afb5dc0",
   "metadata": {},
   "source": [
    "## Okay, I hope you've stopped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecd7fc8",
   "metadata": {},
   "source": [
    "## Now, we can see the good stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aca24d8",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<hr/>\n",
    "<hr/>\n",
    "\n",
    "\n",
    "# This is where the good stuff will go\n",
    "\n",
    "And you know this stuff will be good.\n",
    "\n",
    "<hr/>\n",
    "<hr/>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf7ae60",
   "metadata": {},
   "source": [
    "## Output for Description and Application:\n",
    "\n",
    "### &lt;FILL THIS IN&gt;\n",
    "\n",
    "@TODO : I need to look at what I've done here in previous versions.\n",
    "\n",
    "### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c55c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #######################\n",
    "# # No need to run again\n",
    "# #####\n",
    "# !powershell -c (Get-Date -UFormat \"%s_%Y%m%dT%H%M%S%Z00\") -replace '[.][0-9]*_', '_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1acab5",
   "metadata": {},
   "source": [
    "The output when I actually did this was\n",
    "\n",
    "```\n",
    "1693128500_20230827T092820-0600\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e01967",
   "metadata": {},
   "source": [
    "## Future Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779b13da",
   "metadata": {},
   "source": [
    "- Look at ranking, counts, percentage, etc. for FamilySearch's (job description's) top 25 words as found in my (job application's) word counts, then vice-versa. \n",
    "  - Code setup completed 2023-08-20. Putting all 25 in would make a very busy display, so I just did a few.\n",
    "- Get rid of words that are necessary for grammar, but which don't matter too much in determining whether the two documents match up. (Found term on 2023-08-07. It's \"stopwords\".)\n",
    "  - Completed 2023-08-09"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e7f734",
   "metadata": {},
   "source": [
    "**Some new future steps**\n",
    "\n",
    "- Do word counts for the pair of top 25, but then also do the fraction each word comprises of the whole (non-stopword) text.\n",
    "  - Completed sometime before 2023-08-27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d73f0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
